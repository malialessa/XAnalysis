# ai_analyzer.py
import vertexai
from vertexai.generative_models import GenerativeModel, Part, Content
from vertexai.language_models import TextEmbeddingModel
import pandas as pd
from sklearn.metrics.pairwise import cosine_similarity
import numpy as np
import json
import re

# Fun√ß√£o para inicializar o Vertex AI
def initialize_vertex_ai(project_id: str, location: str):
    vertexai.init(project=project_id, location=location)

# Fun√ß√£o para extrair requisitos usando Gemini
def extract_requirements_with_gemini(edital_text: str) -> dict:
    """
    Extrai informa√ß√µes estruturadas de requisitos do edital usando o modelo Gemini.
    """
    model = GenerativeModel("gemini-2.5-flash") # Ou "gemini-1.0-pro"

    # Prompt mais robusto e com exemplos para guiar a extra√ß√£o
    prompt = f"""
    Dado o seguinte texto de edital, extraia as seguintes informa√ß√µes no formato JSON.
    Se uma informa√ß√£o n√£o for encontrada, use "N/A".
    Para datas e valores, extraia-os no formato mais padronizado poss√≠vel.
    Identifique claramente os requisitos de habilita√ß√£o (jur√≠dica, t√©cnica, fiscal, econ√¥mico-financeira) e os requisitos do objeto/qualifica√ß√£o t√©cnica espec√≠ficos do servi√ßo/produto.
    
    Estrutura JSON esperada:
    {{
        "Objeto": "...",
        "Orgao": "...",
        "TipoJulgamento": "...",
        "ValorEstimado": "...",
        "Datas": {{
            "AcolhimentoPropostasInicio": "DD/MM/AAAA",
            "AcolhimentoPropostasFim": "DD/MM/AAAA HH:MM",
            "AberturaPropostas": "DD/MM/AAAA HH:MM",
            "DisputaPrecos": "DD/MM/AAAA HH:MM"
        }},
        "RequisitosHabilitacao": {{
            "Juridica": ["Prova de registro comercial", "Ato constitutivo/estatuto social", ...],
            "Fiscal": ["Prova de inscri√ß√£o CNPJ", "Regularidade Fazenda Federal/Estadual/Municipal", "Regularidade Seguridade Social/FGTS", ...],
            "EconomicoFinanceira": ["Certid√£o Negativa de Fal√™ncia", "Balan√ßo Patrimonial com √≠ndices (LG, SG, LC)", "Patrim√¥nio L√≠quido m√≠nimo (se aplic√°vel)", ...],
            "TecnicaGeral": ["Atestado(s) de capacidade t√©cnica", "Certifica√ß√µes", "Comprova√ß√£o de v√≠nculo do profissional", ...]
        }},
        "RequisitosObjetoQualificacaoTecnicaEspecifica": [
            {{
                "Tipo": "Servi√ßo/Produto",
                "Descricao": "...",
                "Detalhes": ["...", "..."],
                "QuantitativoMinimo": "...",
                "CertificacaoExigida": "...",
                "PrazosEspecificos": "...",
                "MencaoIA": "Sim/N√£o"
            }}
            // Pode haver m√∫ltiplos objetos/itens
        ],
        "CondicoesEspecializadas": {{
            "POC": "Sim/N√£o",
            "Garantias": ["...", "..."],
            "CriteriosEliminatorios": ["...", "..."],
            "SubcontratacaoPermitida": "Sim/N√£o"
        }},
        "InformacoesGerais": {{
            "ValidadeProposta": "...",
            "LocalEntregaDocs": "...",
            "ContatoDuvidas": "..."
        }}
    }}

    Texto do Edital:
    {edital_text}
    """

    response = model.generate_content(prompt, generation_config={"response_mime_type": "application/json"})
    
    # O Gemini pode envolver o JSON em '```json\n...\n```'. Limpar isso.
    try:
        json_string = response.text.strip()
        if json_string.startswith("```json") and json_string.endswith("```"):
            json_string = json_string[len("```json"): -len("```")].strip()
        
        # Corre√ß√£o de poss√≠veis erros de formata√ß√£o JSON comuns do LLM
        # Remover v√≠rgulas penduradas antes de chaves de fechamento ou colchetes
        json_string = re.sub(r',\s*([\]}])', r'\1', json_string)
        # Substituir aspas simples por duplas (se o modelo ocasionalmente usar aspas simples)
        json_string = json_string.replace("'", '"')
        # Tentar corrigir chaves de abertura/fechamento que podem estar incorretas
        json_string = re.sub(r'([a-zA-Z0-9_]+)\s*:\s*([^,{}\[\]"]+)', r'"\1": "\2"', json_string)


        extracted_data = json.loads(json_string)
        return extracted_data
    except json.JSONDecodeError as e:
        print(f"Erro ao decodificar JSON do Gemini: {e}")
        print(f"Resposta bruta do Gemini: {response.text}")
        # Tentar uma corre√ß√£o mais agressiva ou retornar um dicion√°rio vazio com erro
        return {"Error": "Failed to parse Gemini JSON output", "RawGeminiOutput": response.text}


# Fun√ß√£o para gerar embeddings
def get_text_embeddings(texts: list[str]) -> list[list[float]]:
    """
    Gera embeddings para uma lista de textos usando o modelo de embedding do Vertex AI.
    """
    model = TextEmbeddingModel.from_pretrained("text-embedding-004") # Ou outro modelo de embedding adequado
    embeddings = model.embed(texts)
    return [embedding.values for embedding in embeddings]

# Fun√ß√£o para normalizar termos (ex: Google Workspace, GWS)
# Pode ser expandida com um dicion√°rio de sin√¥nimos ou com a ajuda de um LLM
def normalize_term(term: str) -> str:
    term = term.lower().strip()
    replacements = {
        "google workspace": "google workspace",
        "gws": "google workspace",
        "contas google": "google workspace contas",
        "google cloud platform": "google cloud platform",
        "gcp": "google cloud platform",
        "armazenamento em nuvem": "cloud storage",
        "nuvem p√∫blica": "cloud public",
        "ia": "intelig√™ncia artificial",
        "intelig√™ncia artificial": "intelig√™ncia artificial",
        "rob√¥": "rob√¥",
        "robotizado": "rob√¥",
        "chatbots": "chatbot",
        "ura": "unidade de resposta aud√≠vel",
        "gera√ß√£o de linguagem natural": "gera√ß√£o de linguagem natural"
    }
    # Tenta encontrar correspond√™ncia exata primeiro, depois parcial
    for key, value in replacements.items():
        if key in term:
            return value
    return term

# Fun√ß√£o para cruzar ativos com requisitos
def cross_reference_assets(extracted_requirements: dict, assets_df: pd.DataFrame) -> pd.DataFrame:
    """
    Cruza os requisitos extra√≠dos do edital com os ativos da planilha.
    Retorna um DataFrame com a an√°lise de atendimento.
    """
    if assets_df.empty:
        return pd.DataFrame(columns=['Requisito', 'Tipo', 'Status', 'Evid√™ncia', 'A√ß√£o Necess√°ria'])

    # Extrair os requisitos relevantes para cruzamento
    all_requirements = []
    
    # Requisitos do Objeto/Qualifica√ß√£o T√©cnica Espec√≠fica
    for req in extracted_requirements.get("RequisitosObjetoQualificacaoTecnicaEspecifica", []):
        all_requirements.append(req.get("Descricao", "") + " " + " ".join(req.get("Detalhes", [])))
    
    # Requisitos de Habilita√ß√£o T√©cnica Geral (se houver men√ß√µes espec√≠ficas de tecnologias/servi√ßos)
    for req_type in ["Juridica", "Fiscal", "EconomicoFinanceira", "TecnicaGeral"]:
        for req_item in extracted_requirements.get("RequisitosHabilitacao", {}).get(req_type, []):
            # Filtra itens gen√©ricos de habilita√ß√£o e foca nos t√©cnicos/de servi√ßo
            if "atestado" in req_item.lower() or "certifica√ß√£o" in req_item.lower() or "servi√ßo especializado" in req_item.lower():
                all_requirements.append(req_item)
    
    all_requirements = [req for req in all_requirements if req.strip()] # Remove vazios

    if not all_requirements:
        return pd.DataFrame(columns=['Requisito', 'Tipo', 'Status', 'Evid√™ncia', 'A√ß√£o Necess√°ria'])

    # Prepare os textos para embeddings (ativos e requisitos)
    assets_texts = assets_df['ProdutosConcatenados'].fillna('') + ' ' + assets_df['Resumo_Objeto_Consolidado'].fillna('')
    assets_embeddings = get_text_embeddings(assets_texts.tolist())
    
    requirements_embeddings = get_text_embeddings(all_requirements)

    analysis_results = []

    for i, req_text in enumerate(all_requirements):
        req_embedding = requirements_embeddings[i]
        
        best_match_score = -1
        best_match_asset_index = -1
        
        # Calcule a similaridade do requisito com todos os ativos
        if assets_embeddings and req_embedding: # Garante que n√£o est√° vazio
            # Reshape para cosine_similarity: (1, n_features) para o vetor √∫nico, (n_samples, n_features) para m√∫ltiplos vetores
            similarities = cosine_similarity(np.array(req_embedding).reshape(1, -1), np.array(assets_embeddings)).flatten()
            best_match_asset_index = np.argmax(similarities)
            best_match_score = similarities[best_match_asset_index]

        status = "üö® N√£o atende / Bloqueador"
        evidence = "‚Äî"
        action_needed = "Buscar solu√ß√£o ou impugnar"

        if best_match_score >= 0.8:  # Limiar de alta similaridade
            matched_asset = assets_df.iloc[best_match_asset_index]
            
            # L√≥gica de Classifica√ß√£o (refinada)
            # Exemplo: verifica√ß√£o de quantitativos e men√ß√µes de IA/GCP
            if "quantitativo m√≠nimo" in req_text.lower():
                # Tente extrair quantitativos do requisito e do ativo para compara√ß√£o
                # Isso exigiria uma l√≥gica de NLP mais avan√ßada para parsear "1.000.000 unidades de consumo" etc.
                pass # L√≥gica complexa, deixada como placeholder
            
            # Normalizar termos para verificar men√ß√µes de tecnologia/IA
            normalized_req = normalize_term(req_text)
            normalized_asset_products = normalize_term(matched_asset['ProdutosConcatenados'].fillna(''))
            normalized_asset_summary = normalize_term(matched_asset['Resumo_Objeto_Consolidado'].fillna(''))
            
            # Verificar se a tecnologia/servi√ßo principal do requisito est√° no ativo
            tech_match = False
            if "google cloud platform" in normalized_req and ("google cloud platform" in normalized_asset_products or "google cloud platform" in normalized_asset_summary):
                tech_match = True
            elif "google workspace" in normalized_req and ("google workspace" in normalized_asset_products or "google workspace" in normalized_asset_summary):
                tech_match = True
            elif "rob√¥" in normalized_req and ("rob√¥" in normalized_asset_products or "rob√¥" in normalized_asset_summary):
                tech_match = True
            elif "intelig√™ncia artificial" in normalized_req and ("intelig√™ncia artificial" in normalized_asset_products or "intelig√™ncia artificial" in normalized_asset_summary):
                tech_match = True
            
            
            # Verifica√ß√£o de Certifica√ß√µes e IA (exemplo, precisa de mapeamento real)
            # 'Certificacoes_Valores_Mencoes_IA' no seu Google Sheet
            asset_certifications_ia = str(matched_asset.get('Certificacoes_Valores_Mencoes_IA', '')).lower()
            
            ia_mentioned_in_asset = "ia" in normalized_asset_products or "ia" in normalized_asset_summary or "intelig√™ncia artificial" in asset_certifications_ia
            
            if tech_match:
                if (matched_asset['Tipo_Contrato'].lower() == 'contrato' and "atestado" not in req_text.lower()) or \
                   (matched_asset['Tipo_Contrato'].lower() == 'atestado' and "atestado" in req_text.lower()):
                    status = "‚úÖ Atende diretamente"
                    evidence = f"{matched_asset['Tipo_Contrato']} - {matched_asset['Nome_Orgao']} - {matched_asset['Ano_Contrato']}"
                    action_needed = "Nenhuma"
                elif matched_asset['Tipo_Contrato'].lower() in ['contrato', 'sow'] and "sow" in matched_asset['ProdutosConcatenados'].lower(): # Exemplo de "indireto"
                    status = "‚ö†Ô∏è Atende indiretamente (combinando contrato e SOW)"
                    evidence = f"{matched_asset['Tipo_Contrato']} + SOW - {matched_asset['Nome_Orgao']} - {matched_asset['Ano_Contrato']}"
                    action_needed = "Detalhar no recurso"
            
            # Refinamento para IA, se o requisito for explicitamente sobre IA e o ativo mencionar IA
            if "intelig√™ncia artificial" in normalized_req or "ia" in normalized_req:
                if ia_mentioned_in_asset:
                    status = "‚úÖ Atende diretamente" # Pode ser mais granular se necess√°rio
                    evidence = f"{matched_asset['Tipo_Contrato']} - {matched_asset['Nome_Orgao']} - {matched_asset['Ano_Contrato']} (com IA)"
                    action_needed = "Nenhuma"
                else:
                    # Se o requisito √© de IA mas o ativo correspondente n√£o menciona IA explicitamente
                    if status != "‚úÖ Atende diretamente": # N√£o sobrescreve se j√° atende diretamente por outro motivo
                        status = "üö® N√£o atende / Bloqueador (Requisito de IA n√£o comprovado no ativo)"
                        action_needed = "Buscar evid√™ncia espec√≠fica de IA ou desenvolver"


        analysis_results.append({
            "Requisito": req_text,
            "Tipo": "Objeto/Qualifica√ß√£o T√©cnica" if "RequisitosObjetoQualificacaoTecnicaEspecifica" in json.dumps(extracted_requirements) else "Habilita√ß√£o T√©cnica",
            "Status": status,
            "Evid√™ncia": evidence,
            "A√ß√£o Necess√°ria": action_needed
        })

    return pd.DataFrame(analysis_results)

# Exemplo de uso (para teste local)
if __name__ == "__main__":
    from config import GOOGLE_CLOUD_PROJECT_ID, GOOGLE_CLOUD_LOCATION, GOOGLE_SHEET_URL, GOOGLE_SHEET_TAB_NAME, SERVICE_ACCOUNT_FILE
    from google_sheets_integrator import get_google_sheet_data
    import os

    # Inicializar Vertex AI
    initialize_vertex_ai(GOOGLE_CLOUD_PROJECT_ID, GOOGLE_CLOUD_LOCATION)

    # Simular texto do edital (use um trecho relevante dos seus PDFs)
    sample_edital_text = """
    2.1. Registro de pre√ßo para contrata√ß√£o de empresa especializada em fornecimento
 de cr√©ditos e em presta√ß√£o de servi√ßos de suporte t√©cnico continuado,
 desenvolvimento e manuten√ß√£o de solu√ß√µes e transfer√™ncia de conhecimento sob
 demanda, na nuvem p√∫blica Google Cloud Plataform (GCP), pelo per√≠odo de 36 (trinta
 e seis) meses, conforme especifica√ß√µes constantes no Edital do Preg√£o Eletr√¥nico n¬∫
 04/2024 e seus anexos.
 6.1.3 Qualifica√ß√£o t√©cnica
 6.1.3.1. A licitante dever√° apresentar Atestado(s) de capacidade t√©cnica de
 fornecido(s) por pessoa jur√≠dica de direito p√∫blico ou privado, que comprove(m) que a
 licitante j√° forneceu o servi√ßo especializado no fornecimento de cr√©ditos de nuvem
 p√∫blica Google Cloud Plataform (GCP) pelo per√≠odo m√≠nimo de 12 meses.
 6.1.3.2. Para fins da comprova√ß√£o de aptid√£o para execu√ß√£o de servi√ßo de
 complexidade tecnol√≥gica e operacional equivalente ou superior com o objeto desta
 contrata√ß√£o, os atestados dever√£o dizer respeito a contratos executados com vig√™ncia
 m√≠nima de doze meses, por meio da apresenta√ß√£o de certid√µes ou atestados, por
 pessoas jur√≠dicas de direito p√∫blico ou privado, com as seguintes caracter√≠sticas
 m√≠nimas:
 a) Demonstra√ß√£o de provimento de subscri√ß√µes de servi√ßos Google Cloud;
 b) Demonstra√ß√£o de execu√ß√£o de pelo menos um servi√ßo especializado na
 plataforma Google Cloud Platform,
 c) O gerenciamento e a opera√ß√£o de inst√¢ncias de m√°quinas virtuais e de
 inst√¢ncias de banco de dados em ambiente de nuvem p√∫blica Google
 Cloud;
 g) Migra√ß√£o de pelo menos 1 (um) banco de dados legado, de ambiente on-
 premise, para um banco de dados gerenciado nativo de um provedor de
 nuvem p√∫blica.
 h) Volume m√≠nimo de 1.000.000 (um milh√£o) de unidades de consumo em
 nuvem ou moeda equivalente (R$, USN, CSN, USIN).
 Dever√° ser
 comprovada execu√ß√£o do montante m√≠nimo informado, sendo vetadas
 apresenta√ß√µes apenas de valores contratuais totais.
 6.1.5. Caso n√£o seja o fabricante, a LICITANTE dever√° apresentar documento
 que comprove estar autorizada e credenciada a comercializar os produtos
 dispon√≠veis da Google Cloud Plataform (GCP), sendo um "premier partner".
 6.1.6. Declara√ß√£o que det√©m a quantidade m√≠nima e profissionais em seu quadro
 ou prestadores de servi√ßo certificados com o objetivo de garantir o m√≠nimo de
 qualidade na presta√ß√£o de servi√ßos em rela√ß√£o ao provedor de nuvem
 oferecido (comprovada na assinatura do contrato): no m√≠nimo 2 (dois)
 profissionais com certifica√ß√£o de arquitetura em nuvem;
    """
    
    # Simular dados de ativos da planilha (para testes sem acessar a API real repetidamente)
    # Em um ambiente real, voc√™ carregaria isso de google_sheets_integrator
    try:
        if os.path.exists(SERVICE_ACCOUNT_FILE):
            ativos_df_test = get_google_sheet_data(GOOGLE_SHEET_URL, GOOGLE_SHEET_TAB_NAME, SERVICE_ACCOUNT_FILE)
        else:
            print("AVISO: SERVICE_ACCOUNT_FILE n√£o encontrado. Usando DataFrame de teste mock.")
            # Mock de dados se o arquivo de servi√ßo n√£o estiver dispon√≠vel
            ativos_data = {
                'ID': [1, 2, 3],
                'Tipo_Contrato': ['Atestado', 'Contrato', 'Certifica√ß√£o'],
                'Nome_Orgao': ['MPPE', 'TJES', 'Empresa X'],
                'Ano_Contrato': [2024, 2023, 2022],
                'Resumo_Objeto_Consolidado': [
                    'Fornecimento de 1.200.000 unidades de consumo Google Cloud Platform (GCP) com suporte t√©cnico e migra√ß√£o de banco de dados.',
                    'Presta√ß√£o de servi√ßos de desenvolvimento de software em nuvem, incluindo uso de IA para otimiza√ß√£o de processos.',
                    'Certifica√ß√£o ISO 27001 e parceria Google Cloud Premier Partner.'
                ],
                'ProdutosConcatenados': [
                    'Google Cloud Platform, GCP Storage, Google Kubernetes Engine, BigQuery, 1.2M unidades',
                    'Desenvolvimento de Chatbot com IA, Machine Learning, APIs, Google Workspace',
                    'ISO 27001, Google Cloud Premier Partner'
                ],
                'Certificacoes_Valores_Mencoes_IA': [
                    'Certifica√ß√£o GCP Professional Cloud Architect, Men√ß√£o de IA em projetos',
                    'Men√ß√£o de IA em SOW, Certifica√ß√£o Scrum Master',
                    'Certifica√ß√£o ISO 27001, Google Cloud Premier Partner'
                ]
            }
            ativos_df_test = pd.DataFrame(ativos_data)


    except Exception as e:
        print(f"Erro ao carregar dados da planilha para teste de ai_analyzer: {e}")
        ativos_df_test = pd.DataFrame() # DataFrame vazio para evitar quebra

    print("--- EXTRAINDO REQUISITOS COM GEMINI ---")
    extracted_reqs = extract_requirements_with_gemini(sample_edital_text)
    print(json.dumps(extracted_reqs, indent=2, ensure_ascii=False))

    print("\n--- CRUZANDO ATIVOS COM REQUISITOS ---")
    analysis_df = cross_reference_assets(extracted_reqs, ativos_df_test)
    print(analysis_df.to_markdown(index=False))